{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2197,"status":"ok","timestamp":1663742788323,"user":{"displayName":"이성준","userId":"00966410257643745737"},"user_tz":-540},"id":"JAUqUCb_cB3L","outputId":"3ee488a4-d3d1-4d6b-abae-57b6a9596af4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1663742788323,"user":{"displayName":"이성준","userId":"00966410257643745737"},"user_tz":-540},"id":"E1VkNsU4b4j0","outputId":"d395a611-3d64-4371-bad2-1feec89dbe82"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ml_pjct1\n"]}],"source":["cd /content/drive/MyDrive/ml_pjct1"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1663742788323,"user":{"displayName":"이성준","userId":"00966410257643745737"},"user_tz":-540},"id":"zpEo-iGHQ-m6","outputId":"96699347-d435-4e85-d722-c4dacc6a29c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["a_exsrc10.png  a_exsrc8.png        Car_Detection.ipynb     \u001b[0m\u001b[01;34mPpl_cropImg\u001b[0m/\n","a_exsrc11.png  a_exsrc9.png        c_exsrc1.png            \u001b[01;34mPpl_face\u001b[0m/\n","a_exsrc12.png  a_FINAL_RESULT.png  Contour_candidates.png  \u001b[01;34mPpl_faceBlurred\u001b[0m/\n","a_exsrc13.png  b_ppl1.jpeg         contouring.png          Preprocess.png\n","a_exsrc1.png   b_ppl2.png          final_res.png           Rotated.png\n","a_exsrc2.png   b_ppl3.png          grayscaled_plate.png    Start.png\n","a_exsrc3.png   b_ppl4.png          ML_BLURcar.ipynb        z_FINALFINAL.png\n","a_exsrc4.png   b_ppl5.png          ML_BLURimg.ipynb        z_FINAL_RESULT.png\n","a_exsrc5.png   b_ppl6.png          Plate_Contour.png\n","a_exsrc6.png   \u001b[01;34mCar_Blurred\u001b[0m/        Possible_contours.png\n","a_exsrc7.png   \u001b[01;34mCar_cropImg\u001b[0m/        \u001b[01;34mPpl_Blurred\u001b[0m/\n"]}],"source":["ls"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16665,"status":"ok","timestamp":1663742804987,"user":{"displayName":"이성준","userId":"00966410257643745737"},"user_tz":-540},"id":"Nou_pM-h8hCO","outputId":"c171142c-3c19-44c3-e822-6d981c18ebea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","tesseract-ocr-kor is already the newest version (4.00~git24-0e00fe6-1.2).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'sudo apt autoremove' to remove it.\n","0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pytesseract in /usr/local/lib/python3.7/dist-packages (0.3.10)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from pytesseract) (21.3)\n","Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.7/dist-packages (from pytesseract) (9.0.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=21.3->pytesseract) (3.0.9)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: Pillow==9.0.0 in /usr/local/lib/python3.7/dist-packages (9.0.0)\n"]}],"source":["!sudo apt install tesseract-ocr-kor\n","!pip install pytesseract\n","!pip install Pillow==9.0.0"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"nd793Z7jZWKp","executionInfo":{"status":"ok","timestamp":1663742810212,"user_tz":-540,"elapsed":5236,"user":{"displayName":"이성준","userId":"00966410257643745737"}}},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","import matplotlib.pyplot as plt\n","import tempfile\n","from six.moves.urllib.request import urlopen\n","from six import BytesIO\n","import numpy as np\n","from PIL import Image\n","from PIL import ImageColor\n","from PIL import ImageDraw\n","from PIL import ImageFont\n","from PIL import ImageOps\n","import time\n","import os\n","import copy\n","import cv2\n","import pytesseract\n","\n","from google.colab.patches import cv2_imshow"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"604tg4hOa-Ye","executionInfo":{"status":"ok","timestamp":1663742911928,"user_tz":-540,"elapsed":101718,"user":{"displayName":"이성준","userId":"00966410257643745737"}}},"outputs":[],"source":["module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n","\n","detector = hub.load(module_handle).signatures['default']"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"KigbzO_U18_2","executionInfo":{"status":"ok","timestamp":1663752536757,"user_tz":-540,"elapsed":583,"user":{"displayName":"이성준","userId":"00966410257643745737"}}},"outputs":[],"source":["def Blur_Plate(path):\n","  try:\n","    img = cv2.imread('Car_cropImg/'+str(path))\n","    orig_img = img.copy()\n","    height, width, channel = img.shape\n","    imgray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","    plt.figure(figsize=(12,8))\n","    plt.subplot(121),plt.imshow(img[:,:,::-1],'gray')\n","    plt.subplot(122),plt.imshow(imgray,'gray')\n","    plt.axis('off')\n","    plt.savefig(\"Start\")\n","    plt.show()\n","    #=============================================================================\n","    # Edge를 뚜렷하게 하기 위해 가우시안 블러 적용\n","    blur = cv2.GaussianBlur(imgray,(5,5),0)\n","\n","    # Adaptive Threshold 적용\n","    thr = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n","    plt.figure(figsize=(20,20))\n","\n","    # dilation - erode with / without blur \n","    kernel = np.ones((3,3),np.uint8)\n","    dil = cv2.dilate(blur,kernel,iterations=1)\n","    ero = cv2.erode(blur,kernel,iterations=1)\n","    morph = dil - ero\n","\n","    kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n","\n","    topHat = cv2.morphologyEx(imgray, cv2.MORPH_TOPHAT, kernel2)\n","    blackHat = cv2.morphologyEx(imgray, cv2.MORPH_BLACKHAT, kernel2)\n","\n","    imgGrayscalePlusTopHat = cv2.add(imgray, topHat)\n","    subtract = cv2.subtract(imgGrayscalePlusTopHat, blackHat)\n","    thr2 = cv2.adaptiveThreshold(subtract,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n","    \n","    # cv2_imshow(thr)\n","    # cv2_imshow(morph)\n","    # cv2_imshow(imgray)\n","\n","    plt.figure(figsize=(12,8))\n","    plt.subplot(221), plt.imshow(blur,'gray')\n","    plt.title(\"blurred\")\n","    plt.subplot(222), plt.imshow(thr,'gray')\n","    plt.title(\"after Adaptive Threshold\")\n","    plt.subplot(223), plt.imshow(morph,'gray')\n","    plt.title(\"Dilation - Erode (with blur)\")\n","    plt.subplot(224), plt.imshow(thr2,'gray')\n","    plt.title(\"top-black AT\")\n","    plt.savefig(\"Preprocess\")\n","    plt.show()\n","    #=============================================================================\n","    # canny 하지 않고\n","    # 그냥 Adaptive Thresh가 젤 잘나옴 \n","    orig_img = img.copy()\n","    cnts,contours = cv2.findContours(thr,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)[1], cv2.findContours(thr,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)[0]\n","    contours_dict = []\n","    pos_cnt = list()\n","    box1 = list()\n","\n","    contours_dict = []\n","\n","    for contour in contours:\n","        x, y, w, h = cv2.boundingRect(contour)\n","        cv2.rectangle(orig_img, pt1=(x, y), pt2=(x+w, y+h), color=(0, 255, 0), thickness=2)\n","        \n","        # insert to dict\n","        contours_dict.append({\n","            'contour': contour,\n","            'x': x,\n","            'y': y,\n","            'w': w,\n","            'h': h,\n","            'cx': x + (w / 2),\n","            'cy': y + (h / 2)\n","        })\n","\n","    plt.figure(figsize=(12,8))         \n","    plt.imshow(orig_img[:,:,::-1])   \n","    plt.savefig(\"Contour_candidates\")\n","    plt.show()  \n","    #=============================================================================\n","    orig_img = img.copy()\n","    count = 0\n","\n","    for d in contours_dict:\n","        rect_area = d['w']*d['h'] # 영역 크기\n","        aspect_ratio = d['w'] / d['h']\n","        \n","        if (aspect_ratio >= 0.3) and (aspect_ratio <= 1.0) and (rect_area >= 100) and (rect_area <= 800):\n","            cv2.rectangle(orig_img,(d['x'],d['y']),(d['x']+d['w'],d['y']+d['h']),(0,255,0),2)\n","            d['idx'] = count\n","            count += 1\n","            pos_cnt.append(d)\n","            \n","\n","    plt.figure(figsize=(20,20))         \n","    plt.imshow(orig_img[:,:,::-1])\n","    plt.savefig(\"Possible_contours\")\n","    plt.show()\n","    #=============================================================================  \n","    MAX_DIAG_MULTIPLYER = 5 # contourArea의 대각선 x5 안에 다음 contour가 있어야함\n","    MAX_ANGLE_DIFF = 12.0  # contour와 contour 중심을 기준으로 한 각도가 n 이내여야함\n","    MAX_AREA_DIFF = 0.5 # contour간에 면적 차이가 크면 인정하지 않겠다.\n","    MAX_WIDTH_DIFF = 0.8 # contour간에 너비 차이가 크면 인정 x\n","    MAX_HEIGHT_DIFF = 0.2 # contour간에 높이 차이가 크면 인정 x\n","    MIN_N_MATCHED = 4 # 위의 조건을 따르는 contour가 최소 3개 이상이어야 번호판으로 인정\n","    orig_img = img.copy()\n","    def find_number(contour_list):\n","        matched_result_idx = []\n","        \n","        # contour_list[n]의 keys = dict_keys(['contour', 'x', 'y', 'w', 'h', 'cx', 'cy', 'idx'])\n","        for d1 in contour_list:\n","            matched_contour_idx = []\n","            for d2 in contour_list:      # for문을 2번 돌면서 contour끼리 비교해줄 것\n","                if d1['idx'] == d2['idx']:   # idx가 같다면 아예 동일한 contour이기에 패스\n","                    continue\n","                    \n","                dx = abs(d1['cx']-d2['cx'])  # d1, d2 중앙점 기준으로 x축의 거리\n","                dy = abs(d1['cy']-d2['cy'])  # d1, d2 중앙점 기준으로 y축의 거리\n","                # 이를 구한 이유는 대각 길이를 구하기 위함 / 피타고라스 정리\n","                \n","                # 기준 Contour 사각형의 대각선 길이 구하기\n","                diag_len = np.sqrt(d1['w']**2+d1['w']**2)\n","                \n","                # contour 중심간의 대각 거리\n","                distance = np.linalg.norm(np.array([d1['cx'],d1['cy']]) - np.array([d2['cx'],d2['cy']]))\n","                \n","                # 각도 구하기\n","                # 빗변을 구할 때, dx와 dy를 알기에 tan세타 = dy / dx 로 구할 수 있다. \n","                # 여기서 역함수를 사용하면    세타 =  arctan dy/dx 가 된다.\n","                if dx == 0:\n","                    angle_diff = 90   # x축의 차이가 없다는 것은 다른 contour가 위/아래에 위치한다는 것\n","                else:\n","                    angle_diff = np.degrees(np.arctan(dy/dx))  # 라디안 값을 도로 바꾼다. \n","                \n","                # 면적의 비율 (기준 contour 대비)\n","                area_diff = abs(d1['w'] * d1['h'] - d2['w'] * d2['h']) / (d1['w']*d1['h'])\n","                # 너비의 비율\n","                width_diff = abs(d1['w']-d2['w']) / d1['w']\n","                # 높이의 비율\n","                height_diff = abs(d1['h']-d2['h']) / d2['h']    \n","                    \n","                # 이제 조건에 맞는 idx만을 matched_contours_idx에 append할 것이다.\n","                if distance < diag_len * MAX_DIAG_MULTIPLYER and angle_diff < MAX_ANGLE_DIFF \\\n","                and area_diff < MAX_AREA_DIFF and width_diff < MAX_WIDTH_DIFF \\\n","                and height_diff < MAX_HEIGHT_DIFF:\n","                    # 계속 d2를 번갈아 가며 비교했기에 지금 d2 넣어주고\n","                    matched_contour_idx.append(d2['idx'])\n","                    \n","            # d1은 기준이었으니 이제 append\n","            matched_contour_idx.append(d1['idx'])\n","            \n","            # 앞서 정한 후보군의 갯수보다 적으면 탈락\n","            if len(matched_contour_idx) < MIN_N_MATCHED:\n","                continue\n","            \n","            # 최종 contour를 입력\n","            matched_result_idx.append(matched_contour_idx)\n","            \n","            # 최종에 들지 못한 아닌애들도 한 번 더 비교\n","            unmatched_contour_idx = []\n","            for d4 in contour_list:\n","                if d4['idx'] not in matched_contour_idx:\n","                    unmatched_contour_idx.append(d4['idx'])\n","            \n","            # np.take(a,idx)   a배열에서 idx를 뽑아냄\n","            unmatched_contour = np.take(pos_cnt,unmatched_contour_idx)\n","            \n","            # 재귀적으로 한 번 더 돌림\n","            recursive_contour_list = find_number(unmatched_contour)\n","            \n","            # 최종 리스트에 추가\n","            for idx in recursive_contour_list:\n","                matched_result_idx.append(idx)\n","                \n","            break\n","            \n","        return matched_result_idx\n","\n","    result_idx = find_number(pos_cnt)\n","\n","    matched_result = []\n","\n","    for idx_list in result_idx:\n","        matched_result.append(np.take(pos_cnt,idx_list))\n","        \n","    # pos_cnt 시각화\n","\n","    for r in matched_result:\n","        for d in r:\n","            cv2.rectangle(orig_img,(d['x'],d['y']),(d['x']+d['w'],d['y']+d['h']),(0,255,0),2)\n","            \n","    plt.figure(figsize=(20,20))        \n","    plt.imshow(orig_img[:,:,::-1])\n","    plt.savefig(\"Plate_Contour\")\n","    plt.show()\n","    #=============================================================================\n","    PLATE_WIDTH_PADDING = 1.3 \n","    PLATE_HEIGHT_PADDING = 1.5 \n","    MIN_PLATE_RATIO = 3\n","    MAX_PLATE_RATIO = 10\n","\n","    plate_imgs = []\n","    plate_infos = []\n","\n","    for i, matched_chars in enumerate(matched_result):\n","        sorted_chars = sorted(matched_chars, key=lambda x: x['cx'])\n","\n","        plate_cx = (sorted_chars[0]['cx'] + sorted_chars[-1]['cx']) / 2\n","        plate_cy = (sorted_chars[0]['cy'] + sorted_chars[-1]['cy']) / 2\n","        \n","        # 합집합 구하는 것 처럼 교집합([0]['x']) 제거 \n","        # 그리고 패딩\n","        plate_width = (sorted_chars[-1]['x'] + sorted_chars[-1]['w'] - sorted_chars[0]['x']) * PLATE_WIDTH_PADDING\n","        \n","        sum_height = 0\n","        for d in sorted_chars:\n","            sum_height += d['h']\n","            \n","        # 평균 구하고 패딩\n","        plate_height = int(sum_height / len(sorted_chars) * PLATE_HEIGHT_PADDING)\n","        \n","        # 삐뚫어져있기에 각도를 구해야함 \n","        \n","        # 높이는 알고 빗변도 알기에 세타를 구할 수 있음 (기울어진 정도)\n","        \n","        # 높이\n","        triangle_height = sorted_chars[-1]['cy'] - sorted_chars[0]['cy']\n","        # 빗변\n","        triangle_hypotenus = np.linalg.norm(\n","            np.array([sorted_chars[0]['cx'], sorted_chars[0]['cy']]) - \n","            np.array([sorted_chars[-1]['cx'], sorted_chars[-1]['cy']])\n","        )\n","        # arcsin을 이용함 \n","        angle = np.degrees(np.arcsin(triangle_height / triangle_hypotenus))\n","        \n","        rotation_matrix = cv2.getRotationMatrix2D((plate_cx, plate_cy), angle, scale=1.0)\n","        \n","        img_rotated = cv2.warpAffine(thr, M=rotation_matrix, dsize=(width, height))\n","        \n","        # 원하는 부분만 잘라냄\n","        img_cropped = cv2.getRectSubPix(\n","            img_rotated, \n","            patchSize=(int(plate_width), int(plate_height)), \n","            center=(int(plate_cx), int(plate_cy))\n","        )\n","        # h/w < Min   or   Max < h/w < Min  해당하면 패스  해당하지 않을경우 append\n","        if img_cropped.shape[1] / img_cropped.shape[0] < MIN_PLATE_RATIO or \\\n","        img_cropped.shape[1] / img_cropped.shape[0] < MIN_PLATE_RATIO > MAX_PLATE_RATIO:\n","            continue\n","        \n","        plate_imgs.append(img_cropped)\n","        plate_infos.append({\n","            'x': int(plate_cx - plate_width / 2),\n","            'y': int(plate_cy - plate_height / 2),\n","            'w': int(plate_width),\n","            'h': int(plate_height)\n","        })\n","        \n","        plt.subplot(len(matched_result), 1, i+1)\n","        plt.savefig(\"grayscaled_plate\")\n","        plt.imshow(img_cropped, cmap='gray')\n","    #=============================================================================\n","    plt.figure(figsize=(12,8))\n","    plt.subplot(121), plt.imshow(thr,'gray'), plt.title(\"Original\")\n","    plt.subplot(122), plt.imshow(img_rotated,'gray'), plt.title(\"Rotated\")\n","    plt.savefig(\"Rotated\")\n","    plt.show()\n","    #=============================================================================\n","    MIN_AREA = 80\n","    MIN_WIDTH, MIN_HEIGHT = 2, 8\n","    MIN_RATIO, MAX_RATIO = 0.2, 1.0\n","\n","    longest_idx, longest_text = -1, 0\n","    plate_chars = []\n","\n","    for i, plate_img in enumerate(plate_imgs):\n","        plate_img = cv2.resize(plate_img, dsize=(0, 0), fx=1.6, fy=1.6)\n","        _, plate_img = cv2.threshold(plate_img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n","        \n","        # 위와 같이 contours 다시 찾기\n","        _, contours = cv2.findContours(plate_img, mode=cv2.RETR_LIST, method=cv2.CHAIN_APPROX_SIMPLE)[1], cv2.findContours(plate_img, mode=cv2.RETR_LIST, method=cv2.CHAIN_APPROX_SIMPLE)[0]\n","        \n","        plate_min_x, plate_min_y = plate_img.shape[1], plate_img.shape[0]\n","        plate_max_x, plate_max_y = 0, 0\n","\n","        for contour in contours:\n","            x, y, w, h = cv2.boundingRect(contour)\n","            \n","            area = w * h\n","            ratio = w / h\n","\n","            if area > MIN_AREA \\\n","            and w > MIN_WIDTH and h > MIN_HEIGHT \\\n","            and MIN_RATIO < ratio < MAX_RATIO:\n","                if x < plate_min_x:\n","                    plate_min_x = x\n","                if y < plate_min_y:\n","                    plate_min_y = y\n","                if x + w > plate_max_x:\n","                    plate_max_x = x + w\n","                if y + h > plate_max_y:\n","                    plate_max_y = y + h\n","                    \n","        img_result = plate_img[plate_min_y:plate_max_y, plate_min_x:plate_max_x]\n","        \n","        # 한번더 blur, threshold\n","        img_result = cv2.GaussianBlur(img_result, ksize=(3, 3), sigmaX=0)\n","        _, img_result = cv2.threshold(img_result, thresh=0.0, maxval=255.0, type=cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n","\n","        chars = pytesseract.image_to_string(img_result, lang='kor', config='--psm 7')\n","        \n","        result_chars = ''\n","        has_digit = False\n","        for c in chars:\n","            if ord('가') <= ord(c) <= ord('힣') or c.isdigit():\n","                if c.isdigit():\n","                    has_digit = True\n","                result_chars += c\n","        \n","        print()\n","        print(\"'\" + result_chars + \"'\" + 'blurred')\n","        print()\n","        \n","        plate_chars.append(result_chars)\n","\n","        if has_digit and len(result_chars) > longest_text:\n","            longest_idx = i\n","\n","        plt.subplot(len(plate_imgs), 1, i+1)\n","        plt.imshow(img_result, cmap='gray')\n","    #=============================================================================\n","    info = plate_infos[longest_idx]\n","    chars = plate_chars[longest_idx]\n","\n","    # print(chars)\n","\n","    orig_img = img.copy()\n","\n","    cv2.rectangle(orig_img, pt1=(info['x'], info['y']), pt2=(info['x']+info['w'], info['y']+info['h']), color=(0,255,0), thickness=2)\n","\n","    cv2.imwrite('./res/' +chars[:7] + '.jpg', orig_img)\n","\n","    plt.figure(figsize=(12, 10))\n","    plt.imshow(orig_img[:,:,::-1])\n","    #=============================================================================\n","    info = plate_infos[longest_idx]\n","    chars = plate_chars[longest_idx]\n","\n","    # print(chars)\n","\n","    orig_img2 = img.copy()\n","\n","    # boundingRect 표시!\n","    # cv2.rectangle(orig_img, pt1=(info['x'], info['y']), pt2=(info['x']+info['w'], info['y']+info['h']), color=(0,255,0), thickness=2)\n","\n","    cv2.imwrite('./res/' +chars[:7] + '.jpg', orig_img)\n","\n","    plt.figure(figsize=(12, 10))\n","    plt.imshow(orig_img2[:,:,::-1])\n","    plt.savefig(\"contouring\")\n","    #=============================================================================\n","    # 원본 이미지에서 번호판 영역을 추출합니다\n","    img_m = orig_img2[info['y']:info['y']+info['h'],info['x']:info['x']+info['w']]\n","    plt.imshow(img_m)\n","    plt.show()\n","    # 1. 사각영역을 먼저 골라낸 후\n","    # 2. 잘라낸 이미지의 크기를 축소한다\n","    # 3. 다시 크기를 확대하여 원본 이미지를 대체한다.\n","\n","    img_m_resize = cv2.resize(img_m,(0,0),fx=0.1,fy=0.1)\n","    plt.imshow(img_m_resize)\n","    print(img_m_resize.shape)\n","    #=============================================================================\n","    h,w,_ = img_m.shape\n","    orig_img2 = img.copy()\n","    img_m_resize = cv2.resize(img_m_resize,(w,h))\n","    orig_img2[info['y']:info['y']+info['h'],info['x']:info['x']+info['w']] = img_m_resize\n","    tosave = Image.fromarray(orig_img2[:,:,::-1])\n","    plt.figure(figsize=(12,8))\n","    plt.imshow(orig_img2[:,:,::-1])\n","    plt.savefig(\"final_res\")\n","    plt.show()\n","    tosave.save('Car_Blurred/Blrd'+ str(path))\n","    #=============================================================================\n","    \n","    print()\n","    print()\n","\n","  except:\n","    print()\n","    print(\"NOTHING TO BLUR\")\n","    print()\n","\n"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"SY6K6uu6mZXZ","executionInfo":{"status":"ok","timestamp":1663752537410,"user_tz":-540,"elapsed":15,"user":{"displayName":"이성준","userId":"00966410257643745737"}}},"outputs":[],"source":["def rm(path):\n","  under_path = os.listdir(path)\n","  for i in range (0, len(under_path), 1):\n","    os.remove(path + '/' + under_path[i])\n","    print(str(under_path[i])+' removed')\n","\n","def rmfile(path):\n","  try:\n","    os.remove(path)\n","  except: pass\n","  print(str(path)+' removed')"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"7e5AUJfZaUJp","executionInfo":{"status":"ok","timestamp":1663752537411,"user_tz":-540,"elapsed":14,"user":{"displayName":"이성준","userId":"00966410257643745737"}}},"outputs":[],"source":["def display_image(image):\n","  fig = plt.figure(figsize=(20, 15))\n","  plt.grid(False)\n","  plt.imshow(image)\n","\n","\n","def download_and_resize_image(url, new_width=256, new_height=256,\n","                              display=False):\n","  _, filename = tempfile.mkstemp(suffix=\".jpg\")\n","  response = urlopen(url)\n","  image_data = response.read()\n","  image_data = BytesIO(image_data)\n","  pil_image = Image.open(image_data)\n","  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n","  pil_image_rgb = pil_image.convert(\"RGB\")\n","  pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n","  print(\"Image downloaded to %s.\" % filename)\n","  if display:\n","    display_image(pil_image)\n","  return filename\n","\n","\n","def draw_bounding_box_on_image(image, ymin, xmin, ymax, xmax, color, font, thickness=4, display_str_list=()):\n","  \"\"\"Adds a bounding box to an image.\"\"\"\n","  draw = ImageDraw.Draw(image)\n","  im_width, im_height = image.size\n","  (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n","                                ymin * im_height, ymax * im_height)\n","  draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n","             (left, top)],\n","            width=thickness,\n","            fill=color)\n","\n","  # If the total height of the display strings added to the top of the bounding\n","  # box exceeds the top of the image, stack the strings below the bounding box\n","  # instead of above.\n","  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n","  # Each display_str has a top and bottom margin of 0.05x.\n","  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n","\n","  if top > total_display_str_height:\n","    text_bottom = top\n","  else:\n","    text_bottom = top + total_display_str_height\n","  # Reverse list and print from bottom to top.\n","  for display_str in display_str_list[::-1]:\n","    text_width, text_height = font.getsize(display_str)\n","    margin = np.ceil(0.05 * text_height)\n","    draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n","                    (left + text_width, text_bottom)],\n","                   fill=color)\n","    draw.text((left + margin, text_bottom - text_height - margin),\n","              display_str,\n","              fill=\"black\",\n","              font=font)\n","    text_bottom -= text_height - 2 * margin\n","\n","def draw_boxes(image, boxes, class_names, scores, max_boxes=20, min_score=0.1):\n","  \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n","  colors = list(ImageColor.colormap.values())\n","  cnt = 0\n","  pplcnt = 0\n","  try:\n","    font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\", 50)\n","  except IOError:\n","    print(\"Font not found, using default font.\")\n","    font = ImageFont.load_default()\n","  try:\n","    pplfont = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\", 30)\n","  except IOError:\n","    print(\"Font not found, using default font.\")\n","    pplfont = ImageFont.load_default()\n","\n","\n","  for i in range(0, len(boxes), 1):  \n","    if class_names[i].decode(\"ascii\") == \"Car\" and scores[i] >= min_score :\n","      cnt += 1\n","      ymin, xmin, ymax, xmax = tuple(boxes[i])\n","\n","      abord = False\n","      # afford = 200\n","      # for p in range (0, len(carbox), 1):\n","      #   if (abs(int(xmin*imgX) - carbox[p][0]) <= afford or int(xmin*imgX) >= carbox[p][0]) and (abs(int(ymin*imgY) - carbox[p][1]) <= afford or int(ymin*imgY) >= carbox[p][1]) and (abs(int(xmax*imgX) - carbox[p][2]) <= afford or int(xmax*imgX) <= carbox[p][2]) and (abs(int(ymax*imgY) - carbox[p][3]) <= afford or int(ymax*imgY) <= carbox[p][3]):\n","      #     print(str(len(carbox)), \"already exists\")\n","      #     abord = True\n","\n","      if abord == True:\n","        continue\n","      display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\") + str(len(carbox)), int(100 * scores[i]))\n","      to_append = []\n","      to_append.append(int((xmin*imgX)*(1.05)))\n","      to_append.append(int((ymin*imgY)*(1.05)))\n","      to_append.append(int((xmax*imgX)*(0.95)))\n","      to_append.append(int(ymax*imgY))\n","      to_append = tuple(to_append)\n","      carbox.append(to_append)\n","      color = colors[hash(class_names[i]) % len(colors)]\n","      image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n","      draw_bounding_box_on_image(\n","          image_pil,\n","          ymin,\n","          xmin,\n","          ymax,\n","          xmax,\n","          color,\n","          font,\n","          display_str_list=[display_str])\n","      np.copyto(image, np.array(image_pil))\n","    if class_names[i].decode(\"ascii\") == \"Person\" or class_names[i].decode(\"ascii\") == \"Man\":\n","      pplcnt += 1\n","      ymin, xmin, ymax, xmax = tuple(boxes[i])\n","\n","      abord = False\n","      afford = 48\n","      for p in range (0, len(pplbox), 1):\n","        if (abs(int(xmin*imgX) - pplbox[p][0]) <= afford or int(xmin*imgX) >= pplbox[p][0]) and (abs(int(ymin*imgY) - pplbox[p][1]) <= afford or int(ymin*imgY) >= pplbox[p][1]) and (abs(int(xmax*imgX) - pplbox[p][2]) <= afford or int(xmax*imgX) <= pplbox[p][2]) and (abs(int(ymax*imgY) - pplbox[p][3]) <= afford or int(ymax*imgY) <= pplbox[p][3]):\n","          print(str(len(pplbox)), \"already exists\")\n","          abord = True\n","\n","      if abord == True:\n","        continue\n","\n","      display_str = \"{}\".format(\"Person\" + str(len(pplbox)) + \" \")\n","      to_append = []\n","      to_append.append(int(xmin*imgX))\n","      to_append.append(int(ymin*imgY))\n","      to_append.append(int(xmax*imgX))\n","      to_append.append(int(ymax*imgY))\n","      to_append = tuple(to_append)\n","      pplbox.append(to_append)\n","      color = colors[hash(class_names[i]) % len(colors)]\n","      image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n","      draw_bounding_box_on_image(\n","          image_pil,\n","          ymin,\n","          xmin,\n","          ymax,\n","          xmax,\n","          color,\n","          pplfont,\n","          display_str_list=[display_str])\n","      np.copyto(image, np.array(image_pil))\n","  return image"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"i7C_rrTWbc0M","executionInfo":{"status":"ok","timestamp":1663752537411,"user_tz":-540,"elapsed":14,"user":{"displayName":"이성준","userId":"00966410257643745737"}}},"outputs":[],"source":["def load_img(path):\n","  img = tf.io.read_file(path)\n","  img = tf.image.decode_jpeg(img, channels=3)\n","  return img\n","\n","def run_detector(detector, path):\n","  img = load_img(path)\n","\n","  converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n","  start_time = time.time()\n","  result = detector(converted_img)\n","  end_time = time.time()\n","\n","  result = {key:value.numpy() for key,value in result.items()}\n","\n","  print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n","  print(\"Inference time: \", end_time-start_time)\n","\n","  image_with_boxes = draw_boxes(\n","      img.numpy(), result[\"detection_boxes\"],\n","      result[\"detection_class_entities\"], result[\"detection_scores\"])\n","  \n","  # print(result[\"detection_boxes\"])\n","  # print(result[\"detection_class_entities\"])\n","  # print(result[\"detection_scores\"])\n","\n","  display_image(image_with_boxes)\n"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"Z7AQMyrajA62","executionInfo":{"status":"ok","timestamp":1663752537411,"user_tz":-540,"elapsed":14,"user":{"displayName":"이성준","userId":"00966410257643745737"}}},"outputs":[],"source":["def cropimg(path):\n","  try: \n","    print(\"Found\", str(len(carbox)), \"Car\")\n","    for i in range(0, len(carbox), 1):\n","      print(carbox[i])\n","      orgnimg = Image.open(path)\n","      crpimg = orgnimg.crop(carbox[i])\n","      crpimg.save('Car_cropImg/car'+ str(i) +'.png')\n","      print('car' + str(i) + ' saved')\n","      crpimgBound.append(carbox[i])\n","  except:\n","    print(\"too small to recognize. no need to mosaic\")"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"b5nnULYQOHA6","executionInfo":{"status":"ok","timestamp":1663752537412,"user_tz":-540,"elapsed":14,"user":{"displayName":"이성준","userId":"00966410257643745737"}}},"outputs":[],"source":["def pplcrop(path):\n","  print(\"Found\", str(len(pplbox)), \"Person\")\n","  for i in range(0, len(pplbox), 1):\n","    print(pplbox[i])\n","    orgnimg = Image.open(path)\n","    crpimg = orgnimg.crop(pplbox[i])\n","    crpimg.save('Ppl_cropImg/ppl'+ str(i) +'.png')\n","    print('ppl' + str(i) + ' saved')\n","    crpimgBound.append(pplbox[i])\n","  "]},{"cell_type":"code","execution_count":26,"metadata":{"id":"I0uEnww0RmIO","executionInfo":{"status":"ok","timestamp":1663752537412,"user_tz":-540,"elapsed":14,"user":{"displayName":"이성준","userId":"00966410257643745737"}}},"outputs":[],"source":["def pasteCar(path):\n","  base = Image.open(path)\n","\n","  for i in range(0, len(crpimgBound), 1):\n","    \n","    if crpimgBound[i]: \n","      ImgToPaste = Image.open('Car_Blurred/Blrdcar'+ str(i) + '.png')\n","      base.paste(ImgToPaste, crpimgBound[i][:2])\n","\n","  base.save('z_FINAL_RESULT.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HkIlp0aJQxRb"},"outputs":[],"source":["path = str(input('file to Blur : ')).strip()\n","\n","rm('Car_cropImg')\n","rm('Car_Blurred')\n","rm('Ppl_Blurred')\n","rm('Ppl_cropImg')\n","rm('Ppl_face')\n","rm('Ppl_faceBlurred')\n","rmfile('z_FINAL_RESULT.png')\n","rmfile('z_FINALFINAL.png')\n","\n","carbox = []\n","pplbox = []\n","crpimgBound = []\n","\n","imgsz = Image.open(path).size\n","imgX = imgsz[0]\n","imgY = imgsz[1]\n","\n","run_detector(detector, path)\n","print(carbox)\n","print(pplbox)\n","cropimg(path)\n","pplcrop(path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EZ6twn19bc76"},"outputs":[],"source":["crpimg = os.listdir('Car_cropImg')\n","for i in range(0, len(crpimg), 1):\n","  if i == len(crpimg)-1:\n","    print(crpimg[i], '['+str(i)+']')\n","    continue\n","  print(crpimg[i], '['+str(i)+']', end = \" / \")\n","\n","print()\n","exec = str(input(\"Enter Number of Mosaic Exception: \"))\n","print()\n","\n","exec = exec.split(\",\")\n","for i in range(0, len(exec), 1):\n","  try:\n","    exec[i] = int(exec[i])\n","  except:\n","    exec.remove(exec[i])\n","\n","for i in range(0, len(exec), 1):\n","  crpimg[exec[i]] = False\n","\n","print()\n","\n","for i in range(0, len(crpimg), 1):\n","  if crpimg[i]:\n","    print('Blurring '+ crpimg[i] + \" ···\")\n","    Blur_Plate(crpimg[i])\n","    print(\"Blurred \"+ crpimg[i])\n","\n","print(\"Blurring each image completed\")\n","\n","blrdlst = os.listdir('Car_Blurred')\n","\n","p = []\n","\n","for i in range (0, len(blrdlst), 1):\n","  p.append(int(blrdlst[i][-5]))\n","\n","for i in range(0, len(crpimgBound), 1):\n","  if i in p:\n","    continue\n","  crpimgBound[i] = False\n","\n","pasteCar(path)\n","\n","print(\"Pasting Blurred image completed. Blurring Plate(s) Ended\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8zfcAkdCTob1"},"outputs":[],"source":["def Mosaic(path, ratio=0.05):\n","    src = cv2.imread(path)\n","    pathlst = path.split(\"/\")\n","    small = cv2.resize(src, None, fx=ratio, fy=ratio, interpolation=cv2.INTER_NEAREST)\n","    mosaic = cv2.resize(small, src.shape[:2][::-1], interpolation=cv2.INTER_NEAREST)\n","    SavedPath = 'Ppl_faceBlurred/Blrd_'+pathlst[1]\n","    cv2.imwrite(SavedPath, mosaic)\n","    return SavedPath"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZC-mawcj9asx"},"outputs":[],"source":["def Blur_Face(path, i):\n","  path = 'Ppl_cropImg/'+ path\n","  # openim('Ppl_cropImg/'+ path)\n","  # to_crop_for_Mosaic = cv2.imread(path)\n","  orgn = Image.open(path)\n","  imgsz = orgn.size\n","  imgX, imgY = imgsz[0], imgsz[1]\n","  CropBound = (0, 0, imgX, int(imgY*0.3))\n","  Cropped = orgn.crop(CropBound)\n","  CroppedPath = 'Ppl_face/'+ 'face' + str(i) + '.png'\n","  Cropped.save(CroppedPath)\n","  to_paste_PATH = Mosaic(CroppedPath)\n","  to_paste = Image.open(to_paste_PATH)\n","  orgn.paste(to_paste, CropBound[:2])\n","  orgn.save('Ppl_Blurred/' + to_paste_PATH.split('/')[1])\n","  print('Ppl_Blurred/' + to_paste_PATH.split('/')[1])\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Jz1FOXM1Y7E"},"outputs":[],"source":["pplcrop = os.listdir('Ppl_cropImg')\n","for i in range(0, len(pplcrop), 1):\n","  if i == len(pplcrop)-1:\n","    print(pplcrop[i] + \"[\"+str(i)+\"]\")\n","    print()\n","    break\n","  print(pplcrop[i], end= \" [\" + str(i) + \"]\" + \" / \")\n","\n","if len(pplcrop) == 0: exec = []\n","else: \n","  exec = str(input(\"Enter Number of Mosaic Exception: \"))\n","  print()\n","  exec = exec.split(\",\")\n","  for i in range(0, len(exec), 1):\n","    try:\n","      exec[i] = int(exec[i])\n","    except:\n","      exec.remove(exec[i])\n","\n","for i in range(0, len(exec), 1):\n","  pplcrop[exec[i]] = False\n","\n","for i in range(0, len(pplcrop), 1):\n","  if pplcrop[i]:\n","    print('Blurring '+ pplcrop[i] + \" ···\")\n","    Blur_Face(pplcrop[i], i)\n","    print(\"Blurred \"+ pplcrop[i])\n","    print()\n","\n","Blrdlst = os.listdir('Ppl_Blurred')\n","\n","for i in range(0, len(exec), 1):\n","  Blrdlst.insert(exec[i], False)\n","\n","carBlurred = Image.open('z_FINAL_RESULT.png')\n","for i in range(0, len(pplcrop), 1):\n","  if Blrdlst[i]:\n","    to_paste = Image.open('Ppl_Blurred/' + Blrdlst[i])\n","    carBlurred.paste(to_paste, pplbox[i])\n","\n","carBlurred.save('z_FINALFINAL.png')\n","print('z_FINALFINAL.png SAVED')\n","    "]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[],"authorship_tag":"ABX9TyOPf8E+pn/v5A9aHEhy5A8w"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}